{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "song_generation_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzPiNnIYNMgB",
        "colab_type": "text"
      },
      "source": [
        "An RNN to create songs based on a text file containing an artist's lyrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXJ0dXnbh4A8",
        "colab_type": "code",
        "outputId": "8ff3d349-e942-4d16-fb8a-b10c75297eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "#relevant imports\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "#name of file + a link to it\n",
        "path_to_file = tf.keras.utils.get_file('smokepurpp.txt', 'https://raw.githubusercontent.com/jss5ha/side_projects/master/smokepurpp.txt')\n",
        "\n",
        "\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "\n",
        "chars = sorted(set(text))\n",
        "#print(chars)\n",
        "\n",
        "#numpy arr of chars\n",
        "chararr = np.array(chars)\n",
        "#dict mapping chars to indices in chararr\n",
        "char2num = {u:i for i, u in enumerate(chars)}\n",
        "\n",
        "#check that they match\n",
        "print(chararr)\n",
        "print(char2num)\n",
        "\n",
        "textasnums = np.array([char2num[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/jss5ha/side_projects/master/smokepurpp.txt\n",
            "303104/300771 [==============================] - 0s 0us/step\n",
            "['\\n' '\\r' ' ' '!' '\"' '$' '&' \"'\" '*' ',' '-' '.' '/' '0' '1' '2' '3' '4'\n",
            " '5' '6' '7' '8' '9' ':' ';' '?' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J'\n",
            " 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'a' 'b'\n",
            " 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't'\n",
            " 'u' 'v' 'w' 'x' 'y' 'z' 'ç' 'è' 'é' 'ë' 'ó' '\\u2005' '\\u200a' '–' '—' '‘'\n",
            " '’' '‚']\n",
            "{'\\n': 0, '\\r': 1, ' ': 2, '!': 3, '\"': 4, '$': 5, '&': 6, \"'\": 7, '*': 8, ',': 9, '-': 10, '.': 11, '/': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, ';': 24, '?': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, 'ç': 78, 'è': 79, 'é': 80, 'ë': 81, 'ó': 82, '\\u2005': 83, '\\u200a': 84, '–': 85, '—': 86, '‘': 87, '’': 88, '‚': 89}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lWV_JENOOPN",
        "colab_type": "text"
      },
      "source": [
        "Make training sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jELqx5TFvBiF",
        "colab_type": "code",
        "outputId": "2aa82fbf-16f4-4f31-9358-7a88ac7d9e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "maxseq = 100\n",
        "epoch_examples = len(text)/(maxseq+1)\n",
        "\n",
        "trainset = tf.data.Dataset.from_tensor_slices(textasnums)\n",
        "\n",
        "seqs = trainset.batch(maxseq+1 , drop_remainder = True)\n",
        "\n",
        "def split_input_to_target(seq):\n",
        "  inp = seq[:-1]\n",
        "  tar=seq[1:]\n",
        "  return inp,tar\n",
        "\n",
        "#maps the set to input and the target output\n",
        "trainset = seqs.map(split_input_to_target)\n",
        "\n",
        "\n",
        "#shuffle\n",
        "batch_size = 64\n",
        "buffer_size = 10000\n",
        "\n",
        "trainset = trainset.shuffle(buffer_size).batch(batch_size, drop_remainder = True)\n",
        "\n",
        "print(len(chars))\n",
        "\n",
        "\n",
        "\n",
        "def make_model(voc_size,batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "                              tf.keras.layers.Embedding(voc_size, 256, batch_input_shape = [batch_size, None]),\n",
        "                              tf.keras.layers.GRU(1024, return_sequences = True, stateful = True, recurrent_initializer = 'glorot_uniform'),\n",
        "                              tf.keras.layers.GRU(512,return_sequences = True, stateful = True, recurrent_initializer = 'glorot_uniform'),\n",
        "                              tf.keras.layers.Dense(voc_size)])\n",
        "  return model\n",
        "\n",
        "myModel = make_model(len(chars),64)\n",
        "\n",
        "#she's a beaut\n",
        "print(myModel.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           23040     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3935232   \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (64, None, 512)           2360832   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 90)            46170     \n",
            "=================================================================\n",
            "Total params: 6,365,274\n",
            "Trainable params: 6,365,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz9O7WAooOfv",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC9vZrzNoVMy",
        "colab_type": "code",
        "outputId": "941e012a-4b98-43a6-ad84-e86e5768a9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits = True)\n",
        "myModel.compile(optimizer='adam', loss = loss)\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "\n",
        "history = myModel.fit(trainset, epochs = 30,callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "46/46 [==============================] - 21s 463ms/step - loss: 3.4848\n",
            "Epoch 2/30\n",
            "46/46 [==============================] - 17s 363ms/step - loss: 2.4942\n",
            "Epoch 3/30\n",
            "46/46 [==============================] - 17s 365ms/step - loss: 2.0578\n",
            "Epoch 4/30\n",
            "46/46 [==============================] - 17s 376ms/step - loss: 1.8285\n",
            "Epoch 5/30\n",
            "46/46 [==============================] - 17s 367ms/step - loss: 1.6569\n",
            "Epoch 6/30\n",
            "46/46 [==============================] - 18s 390ms/step - loss: 1.5105\n",
            "Epoch 7/30\n",
            "46/46 [==============================] - 17s 380ms/step - loss: 1.3808\n",
            "Epoch 8/30\n",
            "46/46 [==============================] - 18s 382ms/step - loss: 1.2629\n",
            "Epoch 9/30\n",
            "46/46 [==============================] - 17s 379ms/step - loss: 1.1556\n",
            "Epoch 10/30\n",
            "46/46 [==============================] - 18s 391ms/step - loss: 1.0580\n",
            "Epoch 11/30\n",
            "46/46 [==============================] - 18s 391ms/step - loss: 0.9692\n",
            "Epoch 12/30\n",
            "46/46 [==============================] - 18s 392ms/step - loss: 0.8838\n",
            "Epoch 13/30\n",
            "46/46 [==============================] - 18s 392ms/step - loss: 0.8037\n",
            "Epoch 14/30\n",
            "46/46 [==============================] - 18s 390ms/step - loss: 0.7309\n",
            "Epoch 15/30\n",
            "46/46 [==============================] - 18s 383ms/step - loss: 0.6637\n",
            "Epoch 16/30\n",
            "46/46 [==============================] - 18s 382ms/step - loss: 0.6009\n",
            "Epoch 17/30\n",
            "46/46 [==============================] - 17s 377ms/step - loss: 0.5438\n",
            "Epoch 18/30\n",
            "46/46 [==============================] - 17s 378ms/step - loss: 0.4881\n",
            "Epoch 19/30\n",
            "46/46 [==============================] - 17s 379ms/step - loss: 0.4336\n",
            "Epoch 20/30\n",
            "46/46 [==============================] - 17s 376ms/step - loss: 0.3766\n",
            "Epoch 21/30\n",
            "46/46 [==============================] - 17s 377ms/step - loss: 0.3311\n",
            "Epoch 22/30\n",
            "46/46 [==============================] - 18s 382ms/step - loss: 0.3017\n",
            "Epoch 23/30\n",
            "46/46 [==============================] - 18s 388ms/step - loss: 0.2701\n",
            "Epoch 24/30\n",
            "46/46 [==============================] - 17s 380ms/step - loss: 0.2328\n",
            "Epoch 25/30\n",
            "46/46 [==============================] - 18s 383ms/step - loss: 0.2018\n",
            "Epoch 26/30\n",
            "46/46 [==============================] - 18s 393ms/step - loss: 0.1718\n",
            "Epoch 27/30\n",
            "46/46 [==============================] - 18s 398ms/step - loss: 0.1506\n",
            "Epoch 28/30\n",
            "46/46 [==============================] - 18s 395ms/step - loss: 0.1332\n",
            "Epoch 29/30\n",
            "46/46 [==============================] - 18s 396ms/step - loss: 0.1153\n",
            "Epoch 30/30\n",
            "46/46 [==============================] - 18s 390ms/step - loss: 0.1032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QyEEQevQdV4",
        "colab_type": "text"
      },
      "source": [
        "Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3rrYN-JQfuq",
        "colab_type": "code",
        "outputId": "2fb31acd-1294-45d9-a979-a82f6430c7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "#rebuild the model with a smaller batch size\n",
        "#lets us feed it less starter text\n",
        "\n",
        "predmodel = make_model(len(chars),1)\n",
        "predmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir,))\n",
        "predmodel.build(tf.TensorShape([1,None]))\n",
        "\n",
        "predmodel.summary()\n",
        "\n",
        "\n",
        "#text gen function\n",
        "\n",
        "def textgen (model, len, startstr, temp = 1.001):\n",
        "\n",
        "  startnums= [char2num[i] for i in startstr]\n",
        "  startnums = tf.expand_dims(startnums,0)\n",
        "\n",
        "  rettext = []\n",
        "\n",
        "  model.reset_states()\n",
        "  for j in range(len):\n",
        "    pred = model(startnums)\n",
        "    pred = tf.squeeze(pred,0)\n",
        "\n",
        "    pred = pred/temp\n",
        "    pred_id = tf.random.categorical(pred,num_samples = 1)[-1,0].numpy()\n",
        "\n",
        "    #update input\n",
        "    startnums = tf.expand_dims([pred_id],0)\n",
        "\n",
        "    rettext.append(chararr[pred_id])\n",
        "    #if j // 50 == 0:\n",
        "      #print(rettext)\n",
        "  #print(rettext)\n",
        "  return (''.join(rettext))\n",
        "\n",
        "print('Smoke' + textgen(predmodel, 1000, 'Smoke'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (1, None, 256)            23040     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (1, None, 1024)           3935232   \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (1, None, 512)            2360832   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (1, None, 90)             46170     \n",
            "=================================================================\n",
            "Total params: 6,365,274\n",
            "Trainable params: 6,365,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Smokepurpp and I lean me I'm like, \"Fuck it,\" I OD\n",
            "Feelesst like I pold the street and died\n",
            "She just wanna fuck me 'cause I'm dister\n",
            "Bitch with a thot bitch\n",
            "And I just be poppin' my shit on repeat \n",
            "I just be talkin' my shit\n",
            "Bronauuu bitch I'm smoking on canny\n",
            "I'm with the fuck shit\n",
            "I'm on that fuck shit\n",
            "Hold on, this ain't gon' do\n",
            "I'm \n",
            "For the jeans, I need siver Purpp \n",
            "Bih, bih, bih bih boh\n",
            "Eigin' hoes \n",
            "I'm with the fuck shit\n",
            "I'm on that fuck shit\n",
            "I'm on that ch out the trunk\n",
            "This neck my dick\n",
            "Told alm cookies and rebicks\n",
            "Fut at Free scrape\n",
            "R-Ronger out a tEacher I want the door, bitch, you amound\n",
            "Raf 'bout these youns like I 50lle\n",
            "Yeah, yeah, yeah, yeah\n",
            "I got Bade, young nigga hotter then an attie\n",
            "Six in the artery\n",
            "Got Droat pronks for you?\n",
            "Lil Purpp really got the bands up\n",
            "Lean in my Fanta\n",
            "Came in a two-door Phantom\n",
            "Wock in my Fanta\n",
            "Came in a two-door Phantom\n",
            "Wock in my Fanta\n",
            "Came in a two-door Phantom\n",
            "Wock in this bitch with a MAs it snow\n",
            "I look at my w\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}